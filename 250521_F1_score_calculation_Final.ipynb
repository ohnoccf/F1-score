{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6gcoxU3N8caZg5JOdEjTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohnoccf/F1-score/blob/main/250521_F1_score_calculation_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY32bPjquznr"
      },
      "outputs": [],
      "source": [
        "# In Google Colab, create 3 folders (1, 2, 3) and upload pairs (ground truth, prediction) of images in folder1 (ground truth) and folder2 (prediction).\n",
        "# Run the code and specify the path of each folder (1, 2, 3).\n",
        "# The results are saved to the new csv file in the output folder (folder3)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def load_image_as_binary(file_path, threshold=127):\n",
        "      image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "      if image is None:\n",
        "        raise ValueError(f\"Unable to load image: {file_path}\")\n",
        "      _, binary_image = cv2.threshold(image, threshold, 1, cv2.THRESH_BINARY)\n",
        "      return binary_image\n",
        "\n",
        "def compute_metrics(ground_truth, prediction):\n",
        "    gt_flat = ground_truth.flatten()\n",
        "    pred_flat = prediction.flatten()\n",
        "\n",
        "    acc = accuracy_score(gt_flat, pred_flat)\n",
        "    prec = precision_score(gt_flat, pred_flat, zero_division=0)\n",
        "    rec = recall_score(gt_flat, pred_flat, zero_division=0)\n",
        "    f1 = f1_score(gt_flat, pred_flat, zero_division=0)\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "def main():\n",
        "    print(\"Please enter the following folder paths:\")\n",
        "    input_folder1 = input(\"Enter path to first input (ground truth) folder: \").strip()\n",
        "    input_folder2 = input(\"Enter path to second input (prediction) folder: \").strip()\n",
        "    output_folder = input(\"Enter path to output folder: \").strip()\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "      print(f\"Created output folder: {output_folder}\")\n",
        "\n",
        "    valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')\n",
        "\n",
        "    images1 = sorted([f for f in os.listdir(input_folder1) if f.lower().endswith(valid_extensions)])\n",
        "    images2 = sorted([f for f in os.listdir(input_folder2) if f.lower().endswith(valid_extensions)])\n",
        "\n",
        "    print(f\"\\nFound {len(images1)} valid images in '{input_folder1}'\")\n",
        "    print(f\"Found {len(images2)} valid images in '{input_folder2}'\")\n",
        "\n",
        "    if len(images1) == 0 or len(images2) == 0:\n",
        "      print(\"Error: One of the input folders does not contain any valid images.\")\n",
        "      return\n",
        "\n",
        "    if len(images1) != len(images2):\n",
        "      print(\"Error: The number of images in the two folders does not match.\")\n",
        "      return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for file1, file2 in zip(images1, images2):\n",
        "        path1 = os.path.join(input_folder1, file1)\n",
        "        path2 = os.path.join(input_folder2, file2)\n",
        "        print(f\"\\nProcessing pair: '{file1}' and '{file2}'\")\n",
        "        try:\n",
        "            img1 = load_image_as_binary(path1)\n",
        "            img2 = load_image_as_binary(path2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            continue\n",
        "\n",
        "        if img1.shape != img2.shape:\n",
        "            print(f\"Skipping pair '{file1}' and '{file2}': image dimensions do not match ({img1.shape} vs {img2.shape}).\")\n",
        "            continue\n",
        "\n",
        "        accuracy, precision, recall, f1 = compute_metrics(img1, img2)\n",
        "        print(f\"Metrics for '{file1}' and '{file2}': Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"Image1\": file1,\n",
        "            \"Image2\": file2,\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1\n",
        "        })\n",
        "\n",
        "    if results:\n",
        "        output_csv = os.path.join(output_folder, \"evaluation_metrics.csv\")\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"\\nAll metrics have been saved to: {output_csv}\")\n",
        "    else:\n",
        "        print(\"\\nNo valid image pairs were processed. CSV file was not created.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}